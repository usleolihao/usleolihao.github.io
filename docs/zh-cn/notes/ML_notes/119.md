# 1/19/2021 AI面试百题训练营

|序号| 难度 | 题目 | 注意事项 |
|---| --- | --- | --- |
| 1 | 简单 |  在模型评估过程中，过拟合和欠拟合具体指什么现象 | 如何描述这两个现象 |
| 2 | 中等 |  降低过拟合和欠拟合的方法 | 从多个维度来考虑，比如数据，特征，模型，目标函数等等 |
| 3 | 中等 |  L1和L2正则先验分别服从什么分布 | 可根据L1和L2正则项的数学表达式的形式来分析 |
| 4 | 简单 |  对于树形结构为什么不需要归一化？ | 理解清楚特征归一化所适用的模型场景 |
| 5 | 中等 |  什么是数据不平衡，如何解决？ | 理解数据不平衡会给模型训练带来什么影响 |

## 在模型评估过程中，过拟合和欠拟合具体指什么现象

过拟合是指模型对于训练数据拟合呈过当的情况，反映到评估指标上，就是模型在训练集上的表现好，但是在测试集和新数据上的表现较差。欠拟合指的是模型在训练和预测时表现都不好。用模型在数据上的偏差和方差指标来表示就是。欠拟合时候，偏差和方差都比较大，而过拟合时，偏差较小但方差较大。

## 降低过拟合和欠拟合的方法

### 降低过拟合

- 特征
    + 减少不必要特征
        * 根据特征的重要性，直接删除稀疏特征。
        * 通过手机更多的数据，或者用数据增广的方法，产生更多的训练数据；从而阻止模型收集不相关的特征
- 模型复杂度
    + 降低模型复杂度
        * 神经网络，减少网络层数和神经元个数
        * 决策树模型中降低树的深度，进行剪枝
- 正则化
    + 加入正则化项提高正则化项的系数。
        * 对复杂模型和系数比较大的模型进行惩罚，使得算法倾向于训练简单的模型
- 多模型决策
    + 采用bagging或者stacking的集成方法，将多个模型融合起来共同决策。以减少模型预测的variance
- 模型训练
    + 训练模型时采用早停策略或采用知识蒸馏的方法进行训练
- 数据目标
    + 比如用于分类任务的标签平滑方法，即在One-hot 表示的ground true 标签里面，将值为1的一小部分值减掉，均分到其他为0的位值上。

### 降低欠拟合
- 特征
    + 添加新特征
        * 比如上下文特征
        * ID类特征
        * 组合特征等等
- 模型复杂度
    + 增加模型复杂度
        * 比如在线性模型增加高次项
        * 在神经网络模型中增加网络层数或者神经元个数。
- 正则化
    + 减少正则化项的系数

## L1和L2正则先验分别服从什么分布

L1正则先验分布是Laplace分布，L2正则先验分布是Gaussian分布

## 对于树形结构为什么不需要归一化？

决策树的学习过程本质上是选择合适的特征，分裂并构建树节点的过程；而分裂节点的标准是由树构建前后的信息增益，信息增益比以及基尼系数等指标决定的。这些指标与当前特征值的大小本身并无关系。


## 什么是数据不平衡，如何解决？

数据不平衡主要指的是在有监督机器学习任务中，样本标签值的分布不均匀。这将使得模型更倾向于将结果预测为样本标签分布较多的值，从而使得少数样本的预测性能下降。绝大多数常见的机器学习算法对于不平衡数据集都不能很好地工作。

解决方法：

1. 重新采样训练集
- 欠采样: 减少丰富类的大小来平衡数据集      
- 过采样: 增加稀有样本，通过使用重复，自举或合成少数类重新采样训练集
2.  设计使用不平衡数据集的模型
- 在代价函数中惩罚稀有类别的错误分类。
